{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the data\n",
    "\n",
    "In machine learning, it is necessary to preprocess the data before put it into network as the neural network is sensitive. \n",
    "Most common cases may transfer the data into a specific distribution case, for example, in our indoor localization project, we use\n",
    "```python\n",
    "from sklearn.preprocessing import scale\n",
    "features = scale(np.asarray(dataset.ix[:,0:520]))\n",
    "```\n",
    "to do the transfering.\n",
    "<br>\n",
    "The [`sklearn.preprocessing`](http://scikit-learn.org/stable/modules/preprocessing.html) package provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream estimators.\n",
    "\n",
    "### Standardization, or mean removal and variance scaling\n",
    "\n",
    "Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data: Gaussian with zero mean and unit variance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
